{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto_pometizer, a Markov-chain poetry generator -- RHYME EDITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip to end of notebook to get straight to generating poetry\n",
    "\n",
    "- **Open the json file after \"Second milestone!\" cell) and run the function! No need to download anything :)**\n",
    "\n",
    "\n",
    "- **If running the code from the beginning, you may need to install certain packages, such as [pronouncing](https://github.com/aparrish/pronouncingpy).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pronouncing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from functions import *\n",
    "from RHYME_functions import *\n",
    "\n",
    "# readers and necessary libraries\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "# word segmenter\n",
    "import wordninja\n",
    "\n",
    "# pronouncing library with rhyme detection\n",
    "import pronouncing as pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make API calls and organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to grab author names\n",
    "base_url = \"http://poetrydb.org/author\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function and check out a sample\n",
    "authors = author_grabber(base_url)\n",
    "authors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over authors list to obtain titles for each\n",
    "titles_grouped = [title_grabber(author) for author in authors]\n",
    "\n",
    "# loop over list of lists of titles grouped by author\n",
    "titles = [title for author in titles_grouped for title in author]\n",
    "\n",
    "# check out a sample\n",
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over titles list to obtain poems as strings\n",
    "poems_list = [poem_grabber(title) for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out a sample\n",
    "poems_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure everything got pulled\n",
    "len(titles), len(poems_list), type(poems_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join poems together into one string\n",
    "poems_string = \" \\n \".join(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it some characteristics\n",
    "len(poems_string), type(poems_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE IT\n",
    "# with open(\"poems_raw.txt\", \"w\") as output:\n",
    "#     output.write(poems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First milestone! One very long string of poetry.\n",
    "- **If you have any adjustments before turning into a dictionary, open the text file and proceed from here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from functions import *\n",
    "from RHYME_functions import *\n",
    "\n",
    "# necessary libraries\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# word segmenter\n",
    "import wordninja\n",
    "\n",
    "# LOAD RAW POEM STRING\n",
    "f = open(\"poems_raw.txt\", \"r\")\n",
    "poems_raw = f.read()\n",
    "\n",
    "# check out a sample\n",
    "poems_raw[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I want to keep the newline and tab characters, so I temporarily change them to different words. Since I'm eventually segmenting the string, I chose two words that don't appear in the poetry (which is all pre-1900) and that the segmenter will recognize as a single word.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute endline characters\n",
    "poems_edit = re.sub(r'\\n', 'airplane', poems_raw)\n",
    "\n",
    "# substitute tab characters\n",
    "poems_edit = re.sub(r'\\t', 'automobile', poems_edit)\n",
    "\n",
    "# check out a sample\n",
    "poems_edit[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Since some of the original source material is formatted poorly, especially multiple words jammed together without spaces, I run the WordNinja segmenter to split them up.**\n",
    "- **NOTE: there is some collateral damage here and some words that should not be segmented get segmented. For a different technique using a tokenizer, look at poem_generator_workbook_punct_token.ipynb in the scrap_files folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment poem string into list of words\n",
    "poems_segmented = wordninja.split(poems_edit)\n",
    "\n",
    "# check out a sample\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Find any single letters (other than *a* and *i* and the very poetic *o*) that are hanging around, as they detract from the generated poems.**\n",
    "\n",
    "- **Replace them with 'automobile', which is currently the equivalent of '\\t', because you can never have enough tabs when trying to make a poem look more contemporary :P**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of letters minus a, i, and o\n",
    "single_letters = ['b','c','d','e','f','g','h','j','k','l','m','n','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "# update list of words\n",
    "poems_segmented = [word if word not in single_letters else word.replace(word, 'automobile') for word in poems_segmented]\n",
    "\n",
    "# check out a sample\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Create a dictionary with each word present in the word list (poems_segmented) as the key and each word that follows that now-key as part of a list of values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a dictionary\n",
    "poems_dictionary = defaultdict(list)\n",
    "\n",
    "# create Markov dictionary\n",
    "for current_word, next_word in zip(poems_segmented, poems_segmented[1:]):\n",
    "    poems_dictionary[current_word].append(next_word)\n",
    "\n",
    "# check out a sample\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **After changing the 'airplane' and 'automobile' values back to newline and tab characters via the lines_tabs_creator function, I change their respective keys in the dictionary accordingly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert back to endline and tab characters\n",
    "poems_dictionary = lines_tabs_creator(poems_dictionary)\n",
    "\n",
    "# replace endline and tab keys\n",
    "poems_dictionary['\\n'] = poems_dictionary.pop('airplane')\n",
    "poems_dictionary['\\t'] = poems_dictionary.pop('automobile')\n",
    "\n",
    "# check out a sample\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE IT AS JSON\n",
    "\n",
    "# f = open(\"poems_dictionary.json\",\"w\")\n",
    "# f.write(json.dumps(poems_dictionary))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second milestone! One very big dictionary.\n",
    "- **If you want to get right to generating some poems, proceed from here and run the auto_pometizer function after opening the json file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from functions import *\n",
    "from RHYME_functions import *\n",
    "\n",
    "# library to open json file\n",
    "import json\n",
    "\n",
    "# open big dictionary!\n",
    "with open(\"poems_dictionary.json\", \"r\") as f:\n",
    "    poems_dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " opp rest \n",
      " \t \t which to pursue hereditary tax at times have been \n",
      " and wearisome hours he for in shades \n",
      " wake some poor trim was hung in antioch \n",
      " \t \t saint \n",
      " else who ve use \n",
      " and hora a sound th his fellow servant thy\n"
     ]
    }
   ],
   "source": [
    "# regular generator\n",
    "auto_pometizer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final milestone?! First poetry generator.\n",
    "## THINK AGAIN: Rhyming experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " tinderbox matches carried to weave \n",
      " for to death so dear and nepal \n",
      " earth but never there karat \n",
      " peon a modern s or some signori \n",
      " your fart \n",
      " \t \t all minstrels once arose and clear and cspi \n",
      " awake \t \n",
      " bea \n",
      " she in all\n"
     ]
    }
   ],
   "source": [
    "# generator with end words replaced with rhymes\n",
    "auto_pometizer_endline_rhymer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " kalu glahn \n",
      " phishing to comet \n",
      " at being who loves last to the morningstar brooch you out hi r rodd that excellence \n",
      " she gan the west lie \n",
      " but pre s strand \n",
      " i needs with our hard to climb \n",
      " beheld \n",
      " but have no savage and\n"
     ]
    }
   ],
   "source": [
    "# generator with random words replaced with rhymes\n",
    "auto_pometizer_random_rhymer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " stubbornly flad kriz fried whosoever yuichi mook liz piercey brea calmest hangs \n",
      " \t with a thousandfold sor gov griz prioritized engwall awry happiness lamontagne frost st-john cove fuse deadliest and valk dum zoran scanned \n",
      " api overexpose php bread mich di catamaran resigned \n",
      " \t annett wiz mace peay\n"
     ]
    }
   ],
   "source": [
    "# generator with all words replaced with rhymes\n",
    "auto_pometizer_full_rhymer(poems_dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rudimentary poetry generator (aka auto_pometizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Skip to end of notebook to get straight to generating poetry*\n",
    "* Open json file below (after \"Second milestone!\" cell) and run the function! No need to download anything.\n",
    "* If running the code from the beginning, you may need to install certain packages, such as wordninja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordninja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make API calls and organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://poetrydb.org/author\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = author_grabber(base_url)\n",
    "authors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [title_grabber(author) for author in authors]\n",
    "titles = [title for sublist in titles for title in sublist]\n",
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = [poem_grabber(title) for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure everything got pulled\n",
    "len(titles), len(poems), type(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = \" \\n \".join(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poems), type(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"poems_raw.txt\", \"w\") as output:\n",
    "    output.write(poems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First milestone! One very long string of poetry.\n",
    "* If you have any adjustments before turning into a dictionary, open the text file and proceed from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import re\n",
    "import wordninja\n",
    "from collections import defaultdict\n",
    "\n",
    "f = open(\"poems_raw.txt\", \"r\")\n",
    "poems_raw = f.read()\n",
    "poems_raw[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I want to keep the newline and tab characters, so I temporarily change them to different words. Since I'm eventually segmenting the string, I chose two words that don't appear in the poetry (which is all pre-1900) and that the segmenter will recognize as a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_edit = re.sub(r'\\n', 'airplane', poems_raw)\n",
    "poems_edit = re.sub(r'\\t', 'automobile', poems_edit)\n",
    "poems_edit[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_segmented = wordninja.split(poems_edit)\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find any single letters (other than 'a' and 'i' and the very poetic 'o') that are hanging around, as they detract from the generated poems.\n",
    "\n",
    "* Replace them with 'automobile', which is currently the equivalent of '\\t', because you can never have enough tabs when trying to make a poem look more contemporary :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_letters = ['b','c','d','e','f','g','h','j','k','l','m','n','p','q','r','s','t','u','v','w','x','y','z']\n",
    "poems_segmented = [word if word not in single_letters else word.replace(word, 'automobile') for word in poems_segmented]\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a dictionary with each word present in the word list (poems_segmented) as the key and each word that follows that now-key as part of a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_dictionary = defaultdict(list)\n",
    "\n",
    "for current_word, next_word in zip(poems_segmented, poems_segmented[1:]):\n",
    "    poems_dictionary[current_word].append(next_word)\n",
    "\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After changing the 'airplane' and 'automobile' values back to newline and tab characters via the lines_tabs_creator function, I change their respective keys in the dictionary accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_dictionary = lines_tabs_creator(poems_dictionary)\n",
    "poems_dictionary['\\n'] = poems_dictionary.pop('airplane')\n",
    "poems_dictionary['\\t'] = poems_dictionary.pop('automobile')\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"poems_dictionary.json\",\"w\")\n",
    "f.write(json.dumps(poems_dictionary))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second milestone! One very big dictionary.\n",
    "* If you want to get right to generating some poems, proceed from here and run the auto_pometizer function after opening the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import json\n",
    "\n",
    "with open(\"poems_dictionary.json\", \"r\") as f:\n",
    "    poems_dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pometizer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final milestone for now! First poetry generator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>auto_pometizer</ins>\n",
    "\n",
    "## A Markov-chain poetry generator\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. [Import functions and packages](#Import-functions-and-packages)\n",
    "2. [Scraping and compiling poetry](#Scraping-and-compiling-poetry)\n",
    "3. [Creating Markov chain dictionary](#Creating-Markov-chain-dictionary)\n",
    "4. [Generate!](#Generate!)\n",
    "    - [Regular style](#Regular-style)\n",
    "    - [Rhyming styles](#Rhyming-styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions and packages\n",
    "\n",
    "[[go back to the top](#auto_pometizer)]\n",
    "\n",
    "- If running the code from the beginning, you may need to install certain packages, such as [wordninja](https://github.com/keredson/wordninja). Uncomment the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from functions import *\n",
    "\n",
    "# readers and necessary libraries\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "# word segmenter\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and compiling poetry\n",
    "\n",
    "[[go back to the top](#auto_pometizer)]\n",
    "\n",
    "- Make API calls to obtain all available authors, each author's available poems, and each poem itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to grab author names\n",
    "base_url = \"https://poetrydb.org/author\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam Lindsay Gordon'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of authors and check out a sample\n",
    "authors = author_grabber(base_url)\n",
    "authors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Song of Autumn'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over authors list to obtain titles for each\n",
    "titles_grouped = [title_grabber(author) for author in authors]\n",
    "\n",
    "# loop over list of lists of titles grouped by author\n",
    "titles = [title for author in titles_grouped for title in author]\n",
    "\n",
    "# check out a sample\n",
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following poems were not successfully scraped:\n"
     ]
    }
   ],
   "source": [
    "# if any poems weren't scraped, the title will be listed below this message\n",
    "print('The following poems were not successfully scraped:')\n",
    "# loop over titles list to obtain poems as strings\n",
    "poems_list = [poem_grabber(title) for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where shall we go for our garlands glad \\n at the falling of the year \\n when the burntup banks are yellow and sad \\n when the boughs are yellow and sere \\n where are the old ones that once we had \\n and when are the new ones near \\n what shall we do for our garlands glad \\n at the falling of the year \\n child can i tell where the garlands go \\n can i say where the lost leaves veer \\n on the brownburnt banks when the wild winds blow \\n when they drift through the deadwood drear \\n girl when the garlands of next year glow \\n you may gather again my dear \\n but i go where the last years lost leaves go \\n at the falling of the year',\n",
       " 'the ocean heaves around us still \\n with long and measured swell \\n the autumn gales our canvas fill \\n our ship rides smooth and well \\n the broad atlantics bed of foam \\n still breaks against our prow \\n i shed no tears at quitting home \\n nor will i shed them now \\n \\t \\n against the bulwarks on the poop \\n i lean and watch the sun \\n behind the red horizon stoop  \\n his race is nearly run \\n those waves will never quench his light \\n oer which they seem to close \\n tomorrow he will rise as bright \\n as he this morning rose \\n \\t \\n how brightly gleams the orb of day \\n across the trackless sea \\n how lightly dance the waves that play \\n like dolphins in our lee \\n the restless waters seem to say \\n in smothered tones to me \\n how many thousand miles away \\n my native land must be \\n \\t \\n speak ocean is my home the same \\n now all is new to me  \\n the tropic skys resplendent flame \\n the vast expanse of sea \\n does all around her yet unchanged \\n the wellknown aspect wear \\n oh can the leagues that i have ranged \\n have made no difference there \\n \\t \\n how vivid recollections hand \\n recalls the scene once more \\n i see the same tall poplars stand \\n beside the garden door \\n i see the birdcage hanging still \\n and where my sister set \\n the flowers in the windowsill  \\n can they be living yet \\n \\t \\n let womans nature cherish grief \\n i rarely heave a sigh \\n before emotion takes relief \\n in listless apathy \\n while from my pipe the vapours curl \\n towards the evening sky \\n and neath my feet the billows whirl \\n in dull monotony \\n \\t \\n the sky still wears the crimson streak \\n of sols departing ray \\n some briny drops are on my cheek \\n tis but the salt sea spray \\n then let our barque the ocean roam \\n our keel the billows plough \\n i shed no tears at quitting home \\n nor will i shed them now']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out a sample\n",
    "poems_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3118, 3118, list)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure everything got pulled\n",
    "len(titles), len(poems_list), type(poems_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the Markov chain dictionary, I want to keep in newline and tab characters as if they are words in the poem, so I've added spaces between them and their preceding/following words.\n",
    "- I'll do the same for joining the poems into one big string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join poems together into one string\n",
    "poems_string = ' \\n '.join(poems_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12175686, str)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check it some characteristics\n",
    "len(poems_string), type(poems_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¾ Save/Load poem string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to save\n",
    "# with open('poems_raw.txt', 'w') as output:\n",
    "#     output.write(poems)\n",
    "\n",
    "# # uncomment to load\n",
    "# f = open('poems_raw.txt', 'r')\n",
    "# poems_raw = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Markov chain dictionary\n",
    "\n",
    "[[go back to the top](#auto_pometizer)]\n",
    "\n",
    "- If you have any adjustments before turning into a dictionary, open the text file and proceed from here.\n",
    "- I want to keep the newline and tab characters, so I temporarily change them to different words. Since I'll eventually be segmenting the string, I choose two words that don't appear in the poetry (which is all pre-1900) and that the segmenter will recognize as a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where shall we go for our garlands glad airplane at the falling of the year airplane when the burntup banks are yellow and sad airplane when the boughs are yellow and sere airplane where are the old ones that once we had airplane and when are the new ones near airplane what shall we do for our garlands glad airplane at the falling of the year airplane child can i tell where the garlands go airplane can i say where the lost leaves veer airplane on the brownburnt banks when the wild winds blow air'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substitute endline characters\n",
    "poems_edit = re.sub(r'\\n', 'airplane', poems_raw)\n",
    "\n",
    "# substitute tab characters\n",
    "poems_edit = re.sub(r'\\t', 'automobile', poems_edit)\n",
    "\n",
    "# check out a sample\n",
    "poems_edit[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since some of the original source material is formatted poorly, especially multiple words jammed together without spaces, I run the WordNinja segmenter to split them up.\n",
    "\n",
    "*NOTE: There is some collateral damage here and some words that should not be segmented get segmented. For a different technique using a tokenizer, look at the [tokenized version](poem_generator_workbook_punct_token.ipynb) in the scrap_files folder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane', 'when', 'the', 'burnt', 'up']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segment poem string into list of words\n",
    "poems_segmented = wordninja.split(poems_edit)\n",
    "\n",
    "# check out a sample\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find any single letters (other than *a* and *i* and the very poetic *o*) that are hanging around, as they detract from the generated poems.\n",
    "    - Replace them with 'automobile', which is currently the equivalent of '\\t', because you can never have enough tabs when trying to make a poem look more contemporary :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane', 'when', 'the', 'burnt', 'up']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of letters minus a, i, and o\n",
    "single_letters = ['b','c','d','e','f','g','h','j','k','l','m','n','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "# update list of words\n",
    "poems_segmented = [word if word not in single_letters else word.replace(word, 'automobile') for word in poems_segmented]\n",
    "\n",
    "# check out a sample\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a dictionary with each word present in the word list ```poems_segmented``` as the key and each word that follows that now-key as part of a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['must', 'airplane', 'airplane', 'airplane', 'while']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a dictionary\n",
    "poems_dictionary = defaultdict(list)\n",
    "\n",
    "# create Markov dictionary\n",
    "for current_word, next_word in zip(poems_segmented, poems_segmented[1:]):\n",
    "    poems_dictionary[current_word].append(next_word)\n",
    "\n",
    "# check out a sample\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After changing the 'airplane' and 'automobile' values back to newline and tab characters via the ```lines_tabs_creator``` function, I change their respective keys in the dictionary accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['must', '\\n', '\\n', '\\n', 'while']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# revert back to endline and tab characters\n",
    "poems_dictionary = lines_tabs_creator(poems_dictionary, endline_sub='airplane', tab_sub='automobile')\n",
    "\n",
    "# replace endline and tab keys\n",
    "poems_dictionary['\\n'] = poems_dictionary.pop('airplane')\n",
    "poems_dictionary['\\t'] = poems_dictionary.pop('automobile')\n",
    "\n",
    "# check out a sample\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¾ Save/Load Markov dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to save\n",
    "# with open('poems_dictionary.json', 'w') as output:\n",
    "#     output.write(poems_dictionary)\n",
    "\n",
    "# # uncomment to load\n",
    "# with open(\"poems_dictionary.json\", \"r\") as f:\n",
    "#     poems_dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate!\n",
    "\n",
    "[[go back to the top](#auto_pometizer)]\n",
    "\n",
    "- If you want to get right to generating some poems, proceed from here and run the auto_pometizer function after opening the json file.\n",
    "\n",
    "*NOTE: You must import functions and packages at the beginning of the notebook.*\n",
    "\n",
    "## Regular style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " fuego south of an air \n",
      " but the tale which i would i doubt any knight \n",
      " i break them in a young so loud intemperance subsides soon is thick the cough \n",
      " what need \n",
      " oh that the highest design \n",
      " minot tis pitt \t without any \n",
      " in\n"
     ]
    }
   ],
   "source": [
    "# run the function, which returns a generated poem string, while also printing by default (can be turned off)\n",
    "auto_pome = auto_pometizer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhyming styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " feliciano \n",
      " as all defence while fish knape \n",
      " \t \t and the \t \n",
      " joaquim \n",
      " khat \n",
      " mar you have not the soothing friendships tears in its stride \n",
      " \t \n",
      " and was the acquiescence \n",
      " ye played so old condemns \n",
      " foundered one pervading manifold i want\n"
     ]
    }
   ],
   "source": [
    "# generator with end words replaced with rhymes\n",
    "auto_pome = auto_pometizer(poems_dictionary, to_rhyme='endline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " gesture stiffed \n",
      " \t \n",
      " or silly damian about \n",
      " jac fo there was savory \n",
      " the villagers \n",
      " annunciation lilies cast piss and not in the lambing dulness with your dolly im conjecturing truth by god tho he stands at home o us keep \n",
      " i will \n",
      " \t\n"
     ]
    }
   ],
   "source": [
    "# generator with random words replaced with rhymes\n",
    "auto_pome = auto_pometizer(poems_dictionary, to_rhyme='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " co-workers belove ter ned ag brookes shultz's barrows in the patrolled \n",
      " \t colleague's fate kuan \n",
      " cy fight in rely apart intertan \n",
      " \t says accost in pi worthey rattan yau secrete invoiced neighbouring hamlets scum the futher the sonny souers bizarre the dartt labov the superpowers' \n",
      " creagh\n"
     ]
    }
   ],
   "source": [
    "# generator with all words replaced with rhymes\n",
    "auto_pome = auto_pometizer(poems_dictionary, to_rhyme='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

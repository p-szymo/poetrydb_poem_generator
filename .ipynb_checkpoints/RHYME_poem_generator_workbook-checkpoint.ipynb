{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rudimentary poetry generator - RHYME EDITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip to end of notebook to get straight to generating poetry\n",
    "* Open json file below (after \"Second milestone!\" cell) and run the function! No need to download anything.\n",
    "* If running the code from the beginning, you may need to install certain packages, such as pronouncing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pronouncing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RHYME_functions import *\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import wordninja\n",
    "import pronouncing as pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make API calls and organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://poetrydb.org/author\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = author_grabber(base_url)\n",
    "authors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [title_grabber(author) for author in authors]\n",
    "titles = [title for sublist in titles for title in sublist]\n",
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = [poem_grabber(title) for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(titles), len(poems), type(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = \" \\n \".join(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poems), type(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"poems_raw.txt\", \"w\") as output:\n",
    "    output.write(poems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First milestone! One very long string of poetry.\n",
    "* If you have any adjustments before turning into a dictionary, open the text file and proceed from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"poems_raw.txt\", \"r\")\n",
    "poems_raw = f.read()\n",
    "poems_raw[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to keep the newline and tab characters, so I temporarily change them to different words. Since I'm eventually segmenting the string, I chose two words that don't appear in the poetry (since it's all pre-1900) and that the segmenter will recognize as a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_edit = re.sub(r'\\n', 'airplane', poems_raw)\n",
    "poems_edit = re.sub(r'\\t', ' automobile', poems_edit)\n",
    "poems_edit[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_segmented = wordninja.split(poems_edit)\n",
    "poems_segmented[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary with each word present in the word list (poems_segmented) as the key and each word that follows that now-key as part of a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_dictionary = defaultdict(list)\n",
    "\n",
    "for current_word, next_word in zip(poems_segmented, poems_segmented[1:]):\n",
    "    poems_dictionary[current_word].append(next_word)\n",
    "\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the 'airplane' and 'automobile' values back to newline and tab characters via the lines_tabs_creator function, I change their respective keys in the dictionary accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_dictionary = lines_tabs_creator(poems_dictionary)\n",
    "poems_dictionary['\\n'] = poems_dictionary.pop('airplane')\n",
    "poems_dictionary['\\t'] = poems_dictionary.pop('automobile')\n",
    "poems_dictionary['land'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"poems_dictionary.json\",\"w\")\n",
    "f.write(json.dumps(poems_dictionary))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"poems_dictionary.txt\",\"w\")\n",
    "f.write(str(poems_dictionary))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second milestone! One very big dictionary.\n",
    "* If you want to get right to generating some poems, open the json file and proceed from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RHYME_functions import *\n",
    "import json\n",
    "\n",
    "with open(\"poems_dictionary.json\", \"r\") as f:\n",
    "    poems_dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " raja cool and the warm return \n",
      " the soul was to see the clouds reposed and to the soul of art \n",
      " to join d \n",
      " oh my tongue unknown thou art \n",
      " gloomy presence at best his progeny from pole they streamed through clear \n",
      " that met who track\n"
     ]
    }
   ],
   "source": [
    "auto_pometizer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final milestone?! First poetry generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEXT UP: rhyming experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 50\n",
      "\n",
      "\n",
      "\n",
      " dc a before \n",
      " he extolled \n",
      " but slip from prospero s often from the sylvan cave forlorn moor y correll \n",
      " \t \t \n",
      " \t as the cause ay nor peace \t \n",
      " \t not but a fount begins to the loud as soothed by saint roni on i\n"
     ]
    }
   ],
   "source": [
    "auto_pometizer_endline_rhymer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pometizer_random_rhymer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What length doth thy sweet nothings require? 100\n",
      "e 1\n",
      "trainee\n",
      "will 4\n",
      "gayshill\n",
      "sponde 0\n",
      "\n",
      " 5\n",
      "\n",
      " 22\n",
      "\n",
      " 5\n",
      "first 29\n",
      "guaranty-first\n",
      "with 38\n",
      "and 51\n",
      "such 31\n",
      "nonesuch\n",
      "rash 71\n",
      "rehash\n",
      "near 41\n",
      "zier\n",
      "nonesuch 31\n",
      "touch\n",
      "day 87\n",
      "portray\n",
      "sponde 0\n",
      "\n",
      "\n",
      "\n",
      " sponde trainee \n",
      " i gayshill \n",
      " where it is good \n",
      " \t \t \n",
      " yet prepared i have been f fir planks \n",
      " i \n",
      " o er grieves me guaranty-first against touch were a blessing of mars grown with feeble ones zier he gone \n",
      " you ll affirm d of science and hard \n",
      " making the angelic choirs a boy \n",
      " \t that troilus be a crime was changed \n",
      " how rehash ambition what made love or zone \n",
      " extend \n",
      " within that lie \n",
      " the christmas portray of us \n",
      " no more answer the pity \n",
      " so we not\n"
     ]
    }
   ],
   "source": [
    "auto_pometizer_full_rhymer(poems_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
